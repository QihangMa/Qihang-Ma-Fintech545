{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0dcb214",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc940d",
   "metadata": {},
   "source": [
    "##### Created by Qihang Ma -- 2023.01.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77baf55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kurtosis, skew, t, ttest_1samp\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc7019",
   "metadata": {},
   "source": [
    "## Problem 1 - Prove the skewness and kurtosis are biased or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ca1aa",
   "metadata": {},
   "source": [
    "STEPS:\n",
    "1. Sample 100, 1,000, 10,000 standardized random normal values.\n",
    "2. Calculate the skewness, kurtosis\n",
    "3. Sample the skewness, kurtosis by repeating steps 1 and 2 1000 times.\n",
    "4. Calculate the mean kurtosis and standard deviation.\n",
    "5. If the value is lower than threshold (typically 5%), then reject the hypothesis that the kurtosis function is unbiased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c7be50",
   "metadata": {},
   "source": [
    "*Prove that the skewness and kurtosis are biased when the sample is small and unbiased when the sample is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677c588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestSkewness(sample_num): \n",
    "    samples = 1000\n",
    "\n",
    "    skewness = np.empty(samples)\n",
    "    for i in range(samples):\n",
    "        skewness[i] = skew(np.random.normal(0, 1,sample_num))\n",
    "\n",
    "    print(\"The mean Skewness is {}.\\nThe standard deviation is {}.\" .format(np.mean(skewness), np.std(skewness)))\n",
    "\n",
    "    t_stat, p_val = ttest_1samp(skewness, popmean=0)\n",
    "\n",
    "    alpha = 0.05\n",
    "\n",
    "    if p_val < alpha:\n",
    "        print(\"For skewness, the calculated p-value is {}.\\nReject the null hypothesis.\\n\" .format(p_val))\n",
    "    else:\n",
    "        print(\"For skewness, the calculated p-value is {}.\\nFail to reject the null hypothesis.\\n\" .format(p_val))\n",
    "    return\n",
    "\n",
    "def TestKurtosis(sample_num):\n",
    "    samples = 1000\n",
    "\n",
    "    kurts = np.empty(samples)\n",
    "    for i in range(samples):\n",
    "        kurts[i] = kurtosis(np.random.normal(0, 1,sample_num))\n",
    "\n",
    "    print(\"The mean kurtosis is {}.\\nThe standard deviation is {}.\" .format(np.mean(kurts), np.std(kurts)))\n",
    "\n",
    "    t_stat, p_val = ttest_1samp(kurts, popmean=0)\n",
    "\n",
    "    alpha = 0.05\n",
    "\n",
    "    if p_val < alpha:\n",
    "        print(\"For kurts, the calculated p-value is {}.\\nReject the null hypothesis.\\n\" .format(p_val))\n",
    "    else:\n",
    "        print(\"For kurts, the calculated p-value is {}.\\nFail to reject the null hypothesis.\\n\" .format(p_val))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797ed521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 100 samples: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'kurts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sample:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m samples: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m.\u001b[39mformat(i))\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mTestSkewness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     TestKurtosis(i)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mTestSkewness\u001b[0;34m(sample_num)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(samples):\n\u001b[1;32m      6\u001b[0m     skewness[i] \u001b[38;5;241m=\u001b[39m skew(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m,sample_num))\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe mean Skewness is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThe standard deviation is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mkurts\u001b[49m), np\u001b[38;5;241m.\u001b[39mstd(kurts)))\n\u001b[1;32m     10\u001b[0m t_stat, p_val \u001b[38;5;241m=\u001b[39m ttest_1samp(skewness, popmean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kurts' is not defined"
     ]
    }
   ],
   "source": [
    "sample = [100,1000,10000]\n",
    "for i in sample:\n",
    "    print(\"For {} samples: \" .format(i))\n",
    "    TestSkewness(i)\n",
    "    TestKurtosis(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d93121",
   "metadata": {},
   "source": [
    "## Problem 2 - OLS, MLE, Comparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af5671",
   "metadata": {},
   "source": [
    "Fit the data in problem2.csv using OLS and calculate the error vector. Look at its distribution. How well does it fit the assumption of normally distributed errors?\n",
    "\n",
    "Fit the data using MLE given the assumption of normality. Then fit the MLE using the assumption of a T distribution of the errors. Which is the best fit?\n",
    "\n",
    "What are the fitted parameters of each and how do they compare? What does this tell us about the breaking of the normality assumption in regards to expected values in this case? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820286d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('problem2.csv')\n",
    "data['constant'] = 1\n",
    "x = data['x']\n",
    "X = data[['constant','x']]\n",
    "y = data ['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d948caa0",
   "metadata": {},
   "source": [
    "### Fit with OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model = sm.OLS(y,X).fit()\n",
    "ols_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1796ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = ols_model.resid\n",
    "plt.hist(error, bins = 20, density = True)\n",
    "x_axis = np.linspace(-6, 6, 100)\n",
    "plt.plot(x_axis, norm.pdf(x_axis, 0,1))\n",
    "\n",
    "print(\"The Skewness of error is {}.\\nThe Kurtosis of error is {}.\" .format(skew(error),kurtosis(error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9996763",
   "metadata": {},
   "source": [
    "### Fit with MLE given the assumption of normality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define likelihood function\n",
    "def MLE_Norm(params, x, y):\n",
    "    yhat = params[0] + params[1]*x # predictions\n",
    "    negLL = -1 * np.sum(stats.norm.logpdf(y, yhat, params[2]))\n",
    "    return(negLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_norm = minimize(MLE_Norm, x0=(1,1,1), args=(x, y))\n",
    "results_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088821b",
   "metadata": {},
   "source": [
    "### Fit wit MLE given the assumption of t-distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084989dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define likelihood function\n",
    "def MLE_T(params, x, y):\n",
    "    yhat = params[0] + params[1]*x # predictions\n",
    "    negLL = -1 * np.sum(stats.t.logpdf(y-yhat, params[2], scale=params[3]))\n",
    "    return(negLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# letâ€™s start with some random coefficient guesses and optimize\n",
    "results_t = minimize(MLE_T, x0=(1,1,1,1), args=(x,y))\n",
    "results_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b91bd",
   "metadata": {},
   "source": [
    "### Goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_square(x, y, intercept, beta):   \n",
    "    y_predicted = intercept + beta * x\n",
    "    y_mean = np.mean(y)\n",
    "    error = y - y_predicted\n",
    "    ss_tot = sum((y - y_mean) ** 2)\n",
    "    ss_res = sum((error - np.mean(error)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1edc2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_square_Norm = R_square(x,y,results_norm.x[0],results_norm.x[1])\n",
    "r_square_T = R_square(x,y,results_t.x[0],results_t.x[1])\n",
    "\n",
    "print(\"The R-square for model fitted with MLE given the assumption of Normal Distribution is {}.\" .format(r_square_Norm))\n",
    "print(\"The R-square for model fitted with MLE given the assumption of T Distribution is {}.\" .format(r_square_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e229c90",
   "metadata": {},
   "source": [
    "### Information Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_info_criteria(x, k, loglik):\n",
    "    AIC = 2 * k + 2 * loglik\n",
    "    BIC = k * np.log(len(x)) + 2 * loglik\n",
    "    return AIC, BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d9a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_N, BIC_N = cal_info_criteria(x, 2, results_norm.fun)\n",
    "AIC_T, BIC_T = cal_info_criteria(x, 2, results_t.fun)\n",
    "print(\"AIC for Normal distribution is: {}. BIC: {}\".format(AIC_N, BIC_N))\n",
    "print(\"AIC for T distribution is: {}. BIC: {}\".format(AIC_T, BIC_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb9a870",
   "metadata": {},
   "source": [
    "## Problem 3 - AR, MR Stimulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56597daa",
   "metadata": {},
   "source": [
    "Simulate AR(1) through AR(3) and MA(1) through MA(3) processes. Compare their ACF and PACF graphs. How do the graphs help us to identify the type and order of each process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "nsample = 3000\n",
    "\n",
    "# Simulate AR(1) process\n",
    "ar1 = np.r_[1, 0.6]\n",
    "ma1 = np.array([1])\n",
    "ar1_data = sm.tsa.arma_generate_sample(ar=ar1, ma=ma1, nsample=nsample)\n",
    "\n",
    "# Simulate AR(2) process\n",
    "ar2 = np.r_[1, 0.6, 0.3]\n",
    "ma2 = np.array([1])\n",
    "ar2_data = sm.tsa.arma_generate_sample(ar=ar2, ma=ma2, nsample=nsample)\n",
    "\n",
    "# Simulate AR(3) process\n",
    "ar3 = np.r_[1, 0.6, 0.3, 0.2]\n",
    "ma3 = np.array([1])\n",
    "ar3_data = sm.tsa.arma_generate_sample(ar=ar3, ma=ma3, nsample=nsample)\n",
    "\n",
    "# Simulate MA(1) process\n",
    "ar4 = np.array([1])\n",
    "ma4 = np.r_[1, 0.6]\n",
    "ma1_data = sm.tsa.arma_generate_sample(ar=ar4, ma=ma4, nsample=nsample)\n",
    "\n",
    "# Simulate MA(2) process\n",
    "ar5 = np.array([1])\n",
    "ma5 = np.r_[1, 0.6, 0.3]\n",
    "ma2_data = sm.tsa.arma_generate_sample(ar=ar5, ma=ma5, nsample=nsample)\n",
    "\n",
    "# Simulate MA(3) process\n",
    "ar6 = np.array([1])\n",
    "ma6 = np.r_[1, 0.6, 0.3, 0.2]\n",
    "ma3_data = sm.tsa.arma_generate_sample(ar=ar6, ma=ma6, nsample=nsample)\n",
    "\n",
    "# Plot data, ACF and PACF for each process\n",
    "fig, axs = plt.subplots(6, 3, figsize=(30,45))\n",
    "for i, data in enumerate([ar1_data, ar2_data, ar3_data, ma1_data, ma2_data, ma3_data]):\n",
    "    axs[i, 0].plot(data)\n",
    "    sm.graphics.tsa.plot_acf(data, lags=10, zero=False, ax=axs[i, 1])\n",
    "    sm.graphics.tsa.plot_pacf(data, lags=10, zero=False, ax=axs[i, 2])\n",
    "    axs[i, 0].set_title(f'Stimulation Data for process {i+1}')    \n",
    "    axs[i, 1].set_title(f'ACF for process {i+1}')\n",
    "    axs[i, 2].set_title(f'PACF for process {i+1}')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
